{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6b488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3f0f5fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Distributed Systems\n",
    "## 2021/22\n",
    "\n",
    "Lab 10\n",
    "\n",
    "Nuno Preguiça, Sérgio Duarte, Dina Borrego, João Vilalonga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05850652",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Goals\n",
    "\n",
    "In the end of this lab you should be able to:\n",
    "\n",
    "+ Understand what is Apache Kafka;\n",
    "+ Know how to perform publish/subscribe communications using Kafka;\n",
    "+ Know how to exploit Kafka to perform total order execution of operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c11c30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Apache KAFKA\n",
    "\n",
    "[Kakfa](https://kafka.apache.org/) is an open-source distributed event streaming platform.\n",
    "\n",
    "+ Exposes a topic-based [publish/subscribe](https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern) API. \n",
    "+ Provides **group communication** with ordering and reliability guarantees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0dd9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Apache KAFKA Architecture\n",
    "\n",
    "<img src=\"https://preguica.github.io/sd2122/praticas2122/aula10/kafka-architecture.png\" width=\"50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337abe66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Apache KAFKA - Reliability\n",
    "\n",
    "Events are persisted in a **persistent log**, stored in stable secondary **stable memory** (disk).\n",
    "\n",
    "+ The log survives broker crashes;\n",
    "+ The log is pruned lazily (ex., events in log can last days);\n",
    "+ The log can be replayed from the beginning<br> to receive events published while subscriber was offline;\n",
    "+ Each topic has its own, independent, event log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bf4ffc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Apache KAFKA - Ordering\n",
    "\n",
    "For performance reasons, for each topic, the event log can be **partitioned**.\n",
    "\n",
    "For each topic, events are **totally ordered** within a **given** partition.\n",
    "\n",
    "The event record **offset** defines the ordering of an event within a given partition.\n",
    "\n",
    "For topics that use more than one partition, events are **partially ordered**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f3145",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache KAFKA - Maven Dependencies\n",
    "\n",
    "```xml\n",
    "<dependencies>\n",
    "    <dependency>\n",
    "        <groupId>org.apache.kafka</groupId>\n",
    "        <artifactId>kafka-clients</artifactId>\n",
    "        <version>2.8.1</version>\n",
    "\t</dependency>\n",
    "</dependencies>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e38be8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache KAFKA - Create Publisher\n",
    "\n",
    "```java\n",
    "static final String TOPIC = \"mytopic\";\n",
    "static final String KAFKA_BROKERS = \"localhost:9092\";\n",
    "static final String EVENT_DATA_STR = \"some event data\";\n",
    "\n",
    "var props = new Properties();\n",
    "props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_BROKERS);\n",
    "\n",
    "props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n",
    "props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n",
    "\n",
    "var publisher = new KafkaProducer<String, String>(props);\t\t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300dfe7a",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[KafkaProducer](https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html) represents the event publisher.\n",
    "\n",
    "To create the publisher we need some configuration properties.\n",
    "\n",
    "+ A comma separated list of brokers endpoints (host:port);\n",
    "+ The serializer classes used to encode event data into raw bytes.\n",
    "\n",
    "There are more [configuration properties](https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html) that provide fine control over the behavior of the publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ed8c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache KAFKA - Publishing Events\n",
    "```java\n",
    "var publisher = new KafkaProducer<String, String>(props);\t\t\n",
    "\n",
    "var promise = publisher.send( new ProducerRecord<>(TOPIC, EVENT_DATA_STR));\n",
    "var metadata = promise.get();\n",
    "\t\t\n",
    "long offset = metadata.offset();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b29d529",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Events are published as [producer records](https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/producer/ProducerRecord.html).\n",
    "\n",
    "We need to provide:\n",
    "\n",
    "+ The event **topic**;\n",
    "+ The event **value**;\n",
    "+ Optionally, the event **key** and/or **partition**.\n",
    "\n",
    "The send operation is asynchronous and only returns a [future](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/Future.html) that will hold\n",
    "the event record [metadata](https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/producer/RecordMetadata.html) after completion.\n",
    "\n",
    "To block until the *send* is completed, we call *get()* on the *metadata future*. \n",
    "\n",
    "The event record metadata contains some useful information about the event, including its **offset**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ee320",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache KAFKA - Create Subscriber\n",
    "\n",
    "```java\n",
    "static final String MY_GROUP_ID = \"my_group_id\";\n",
    "static final String REPLAY_FROM_BEGINNING = \"earliest\";\n",
    "static final String KAFKA_BROKERS = \"localhost:9092, kafka:9092\";\n",
    "\n",
    "var props = new Properties();\n",
    "\n",
    "props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_BROKERS);\n",
    "props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "\n",
    "props.put(ConsumerConfig.GROUP_ID_CONFIG, MY_GROUP_ID );\n",
    "props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, REPLAY_FROM_BEGINNING);\n",
    "\n",
    "var consumer = new KafkaConsumer<String, String>(props);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33034a1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[KafkaConsumer](https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html) represents the event subscriber.\n",
    "\n",
    "To create the subscriber we need some configuration properties.\n",
    "\n",
    "+ A comma separated list of brokers endpoints (host:port);\n",
    "+ The deserializer classes used to decode raw bytes to event key and values;\n",
    "+ The group id of the consumer (if multiple consumers share the same group id, consumed events are split among them)\n",
    "+ The mode of event log replay: earliest - from the beggining; latest - the next event to be published.\n",
    "\n",
    "There are more [configuration properties](https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html) that provide fine control over the behavior of the subscriber."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145cfb44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache KAFKA - Subscription and notification\n",
    "\n",
    "```java\n",
    "static final String TOPIC = \"mytopic\";\n",
    "\n",
    "var consumer = new KafkaConsumer<String, String>(props);\n",
    "\n",
    "consumer.subscribe(List.of(TOPIC));\n",
    "\n",
    "consumer.poll(Duration.ofSeconds(10)).forEach( System.out::println );\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0f592",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The consumer can subscribe to multiple topics, supplied as a list.\n",
    "\n",
    "Events are notified as [consumer records](https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRecord.html).\n",
    "\n",
    "The event record contains the event data: **key** and **value**, as well as, *metadata*, <br>namely, the **topic** it belongs to, and the offset, within the **topic partition**.\n",
    "\n",
    "Consuming events is a blocking operation: **poll** blocks for a period of time; <br> and, returns\n",
    "the list of events, ordered according to the semantics:\n",
    " + unordered among topics;\n",
    " + partially ordered among partitions of the same topic;\n",
    " + totally ordered within the same topic partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d0c89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Zookeeper\n",
    "\n",
    "[Zookeeper](https://zookeeper.apache.org/) is a centralized service for highly reliable distributed coordination.\n",
    "\n",
    "Can provide distributed applications with:\n",
    "\n",
    "+ Naming;\n",
    "+ Distributed synchronization;\n",
    "+ **Distributed consensus/elections**;\n",
    "+ Configuration information storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cc62e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Zookeeper\n",
    "\n",
    "Zookeeper provides hierarchical tuple space that stores information in a reliable and **strongly\n",
    "consistent** way.\n",
    "\n",
    "Some relevant aspects of zookeeper:\n",
    "\n",
    "+ Tuples have a *unique name* and optionally a *value* associated. \n",
    " + A tuple is named a **znode** in the zookeeper nomenclature.\n",
    "\n",
    "\n",
    "+ Tuples are hierarchical like the directory structure of a file system. \n",
    " + You can have a tuple named ’zoo’; a child tuple named ‘one’, whose complete name is ‘/zoo/one’\n",
    "\n",
    "\n",
    "+ It is possible to **monitor changes** to a znode (and all its children),<br> and be **notified** by zookeeper whenever a change\n",
    "happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf9eef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zookeeper tuples types\n",
    "\n",
    "There are several kinds of znodes.\n",
    "\n",
    "+ **Persistent** znodes survive the crash of the client that created them;\n",
    "+ **Ephemeral** nodes are deleted automatically when the client session/connection that created them is broken;\n",
    "\n",
    "+ **Persistent_Sequential** and **Ephemeral_Sequential** are nodes whose names are generated automatically in a strictly increasing order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dfeffc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zookeeper - Maven dependencies\n",
    "\n",
    "```xml\n",
    "<dependency>\n",
    "    <groupId>org.apache.zookeeper</groupId>\n",
    "\t<artifactId>zookeeper</artifactId>\n",
    "\t<version>3.8.0</version>\n",
    "</dependency>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393851fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zookeeper - Client session¶\n",
    "\n",
    "```java\n",
    "static final int TIMEOUT = 5000;\n",
    "\n",
    "var connectedSignal = new CountDownLatch(1);\n",
    "\n",
    "client = new ZooKeeper(host, TIMEOUT, (e) -> {\n",
    "    if (e.getState().equals(Watcher.Event.KeeperState.SyncConnected)) {\n",
    "        connectedSignal.countDown();\n",
    "});\n",
    "    \n",
    "connectedSignal.await();\n",
    "// client is now connected...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56c853",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Connection to the Zookeeper server is asynchronous and go throw multiple states.\n",
    "\n",
    "A countdown latch can be used as barrier to only proceed once the connection event is notified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209eb98f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zookeeper - Tuple creation\n",
    "\n",
    "```java\n",
    "public String createNode(String path, byte[] data, CreateMode mode) {\n",
    "    try {\n",
    "        return client.create(path, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, mode);\n",
    "\t} catch (KeeperException.NodeExistsException x) {\n",
    "\t\treturn path;\n",
    "\t} catch (Exception x) {\n",
    "        return null;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Example usages:\n",
    "\n",
    "```java\n",
    "createNode(\"/path\", new byte[0], CreateMode.PERSISTENT)\n",
    "    \n",
    "var new_path = createNode(\"/path\", new byte[0], CreateMode.EPHEMERAL_SEQUENTIAL)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42e7ae",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To create a tuple using a client in a *connected* state, we supply:\n",
    "\n",
    "+ the path (full name) of the tuple;\n",
    "+ the data associated with the tuple;\n",
    "+ the type of node.\n",
    "\n",
    "For **EPHEMERAL_SEQUENTIAL** zknodes the name is created automatically by Zookeeper and is returned\n",
    "by the creation operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91e01b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zookeeper  List Tuple Children \n",
    "\n",
    "```java \n",
    "public List<String> getChildren(String path) {\n",
    "    try {\n",
    "        return client.getChildren(path, false);\n",
    "\t} catch (Exception x) {\n",
    "        x.printStackTrace();\n",
    "\t}\n",
    "\treturn Collections.emptyList();\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c4ff16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zookeeper  List Tuple Children \n",
    "\n",
    "```java \n",
    "public List<String> getChildren(String path, Watcher watcher) {\n",
    "    try {\n",
    "        return client().getChildren(path, watcher);\n",
    "\t} catch (Exception x) {\n",
    "        x.printStackTrace();\n",
    "\t}\n",
    "\treturn Collections.emptyList();\n",
    "}\n",
    "```\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```java\n",
    "getChilden(\"/path\", (e) -> {\n",
    "    // something under '/path' changed...\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d4a01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EXERCISES\n",
    "\n",
    "\n",
    "### Kafka : clients in localhost\n",
    "\n",
    "+ Download and study the sample projects provided.\n",
    "\n",
    "+ Start Kafka with the provided script.\n",
    "\n",
    " `sh start-kafka.sh localhost`\n",
    "\n",
    "\n",
    "+ Run the KafkaSender and KafkaReceiver examples, in eclipse/IDE.\n",
    "\n",
    "\n",
    "### Kafka : clients as docker containers\n",
    "\n",
    "+ Edit KafkaSender and KafkaReceiver and replace the KAFKA_BROKERS constant to \"kafka:9092\"\n",
    "\n",
    "+ Start Kafka with the provided script.\n",
    "\n",
    " `sh start-kafka.sh kafka`\n",
    "\n",
    "\n",
    "+ Build the docker image\n",
    "\n",
    " `mvn clean compile assembly:single docker:build`\n",
    "\n",
    "\n",
    "+ Run KafkaReceiver\n",
    "\n",
    " `docker run -t --network=sdnet sd2122-aula10-kafka java -cp /home/sd/sd.jar sd2122.aula10.kafka.examples.KafkaReceiver`\n",
    "\n",
    "\n",
    "+ Run KafkaSender\n",
    "\n",
    " `docker run -t --network=sdnet sd2122-aula10-kafka java -cp /home/sd/sd.jar sd2122.aula10.kafka.examples.KafkaSender   msg`\n",
    "\n",
    "### TP2 Kafka Replication Helper Code\n",
    "\n",
    "+ The provided *SyncPoint class* is a generic version of the code presented in lectures.\n",
    "\n",
    "+ Check *TotalOrderExecutor class* on how to use SyncPoint class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d166e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
